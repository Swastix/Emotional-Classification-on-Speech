{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f070855a",
   "metadata": {
    "_cell_guid": "a5489c1f-2916-463f-b5e9-befe8b10180d",
    "_uuid": "2518e973-afa5-430e-bef6-e23e45d85a92",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-06-22T07:44:21.982583Z",
     "iopub.status.busy": "2025-06-22T07:44:21.982305Z",
     "iopub.status.idle": "2025-06-22T07:44:37.732372Z",
     "shell.execute_reply": "2025-06-22T07:44:37.731784Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15.755419,
     "end_time": "2025-06-22T07:44:37.733871",
     "exception": false,
     "start_time": "2025-06-22T07:44:21.978452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-22 07:44:24.975172: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750578265.163741      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750578265.219739      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from glob import glob\n",
    "from joblib import Parallel, delayed\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67aec8a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:44:37.740086Z",
     "iopub.status.busy": "2025-06-22T07:44:37.739631Z",
     "iopub.status.idle": "2025-06-22T07:44:37.747732Z",
     "shell.execute_reply": "2025-06-22T07:44:37.747201Z"
    },
    "papermill": {
     "duration": 0.012233,
     "end_time": "2025-06-22T07:44:37.748822",
     "exception": false,
     "start_time": "2025-06-22T07:44:37.736589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def noise(data, noise_factor=0.035):\n",
    "    noise_amp = noise_factor * np.random.uniform() * np.amax(data)\n",
    "    return data + noise_amp * np.random.normal(size=data.shape[0])\n",
    "\n",
    "def stretch(data, rate_min=0.8, rate_max=1.2):\n",
    "    rate = np.random.uniform(low=rate_min, high=rate_max)\n",
    "    return librosa.effects.time_stretch(data, rate=rate)\n",
    "\n",
    "def shift(data):\n",
    "    shift_range = int(np.random.uniform(low=-5, high=5) * 1000)\n",
    "    return np.roll(data, shift_range)\n",
    "\n",
    "def pitch(data, sampling_rate, pitch_steps_min=-4, pitch_steps_max=4):\n",
    "    pitch_steps = np.random.randint(low=pitch_steps_min, high=pitch_steps_max)\n",
    "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_steps)\n",
    "\n",
    "\n",
    "# --- Feature Extraction Function ---\n",
    "def extract_features(data, sampling_rate, n_mels=128, fmax=8000, n_mfcc=40):\n",
    "    stft = np.abs(librosa.stft(data, n_fft=2048, hop_length=512))\n",
    "    mel_spec = librosa.feature.melspectrogram(S=stft**2, sr=sampling_rate, n_mels=n_mels, fmax=fmax)\n",
    "    log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=n_mfcc)\n",
    "    \n",
    "    chroma = librosa.feature.chroma_stft(S=stft, sr=sampling_rate)\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data)\n",
    "    \n",
    "    rmse = librosa.feature.rms(y=data)\n",
    "    \n",
    "    # Concatenate features. Ensure they have compatible dimensions (frames).\n",
    "    # We'll pad them to MAX_FRAMES later.\n",
    "    # For now, we'll concatenate along the feature dimension (axis=0).\n",
    "    \n",
    "    # Ensure all features have the same number of frames for concatenation\n",
    "    min_frames = min(log_mel_spec.shape[1], mfccs.shape[1], chroma.shape[1], zcr.shape[1], rmse.shape[1])\n",
    "    \n",
    "    combined_features = np.vstack([\n",
    "        log_mel_spec[:, :min_frames],\n",
    "        mfccs[:, :min_frames],\n",
    "        chroma[:, :min_frames],\n",
    "        zcr[:, :min_frames],\n",
    "        rmse[:, :min_frames]\n",
    "    ])\n",
    "    \n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5c0e3e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:44:37.753971Z",
     "iopub.status.busy": "2025-06-22T07:44:37.753725Z",
     "iopub.status.idle": "2025-06-22T07:44:44.449354Z",
     "shell.execute_reply": "2025-06-22T07:44:44.448451Z"
    },
    "papermill": {
     "duration": 6.699528,
     "end_time": "2025-06-22T07:44:44.450598",
     "exception": false,
     "start_time": "2025-06-22T07:44:37.751070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total audio files found: 2452\n"
     ]
    }
   ],
   "source": [
    "# Combine all audio files from both folders\n",
    "audio_dirs = [\n",
    "    '/kaggle/input/audio/Audio_Song_Actors_01-24',\n",
    "    '/kaggle/input/audio/Audio_Speech_Actors_01-24'\n",
    "]\n",
    "audio_files = []\n",
    "for d in audio_dirs:\n",
    "    audio_files.extend(glob(os.path.join(d, '**', '*.wav'), recursive=True))\n",
    "print(f\"Total audio files found: {len(audio_files)}\")\n",
    "\n",
    "# Load all_labels.csv for mapping file names to emotions\n",
    "labels_df = pd.read_csv('/kaggle/input/audio/all_labels.csv')\n",
    "labels_dict = {os.path.basename(row['filename']): row['emotion'] for _, row in labels_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1468fdda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:44:44.456442Z",
     "iopub.status.busy": "2025-06-22T07:44:44.456212Z",
     "iopub.status.idle": "2025-06-22T07:47:58.494055Z",
     "shell.execute_reply": "2025-06-22T07:47:58.493263Z"
    },
    "papermill": {
     "duration": 194.042002,
     "end_time": "2025-06-22T07:47:58.495211",
     "exception": false,
     "start_time": "2025-06-22T07:44:44.453209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of combined features per frame: 182\n",
      "Final X shape: (8300, 182, 175, 1)\n"
     ]
    }
   ],
   "source": [
    "# --- Define parameters ---\n",
    "N_MELS = 128 # For Mel Spectrograms\n",
    "N_MFCC = 40 # For MFCCs\n",
    "MAX_FRAMES = 175 # Adjusted based on typical audio duration and feature concatenation\n",
    "\n",
    "# --- process_file function ---\n",
    "def process_file(file_path):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    emotion = labels_dict.get(file_name)\n",
    "    if emotion is None:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data, sr = librosa.load(file_path, duration=3, offset=0.5, sr=22050) \n",
    "        if len(data) < 3 * sr:\n",
    "             return []\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    augmented_datas = [\n",
    "        data,\n",
    "        noise(data),\n",
    "        stretch(data),\n",
    "        pitch(data, sr)\n",
    "    ]\n",
    "    \n",
    "    result = []\n",
    "    for aug_data in augmented_datas:\n",
    "        features = extract_features(aug_data, sr, n_mels=N_MELS, n_mfcc=N_MFCC)\n",
    "        result.append((features, emotion))\n",
    "    return result\n",
    "\n",
    "results = Parallel(n_jobs=4)(delayed(process_file)(f) for f in audio_files)\n",
    "features_and_labels = [item for sublist in results for item in sublist]\n",
    "\n",
    "# Calculate total number of features from extract_features\n",
    "# Get one sample to determine the total number of features (rows in the feature matrix)\n",
    "if features_and_labels:\n",
    "    sample_features = features_and_labels[0][0]\n",
    "    TOTAL_FEATURES = sample_features.shape[0]\n",
    "    print(f\"Total number of combined features per frame: {TOTAL_FEATURES}\")\n",
    "else:\n",
    "    TOTAL_FEATURES = N_MELS + N_MFCC + 12 + 1 + 1 # n_mels + n_mfcc + chroma (12) + zcr (1) + rmse (1)\n",
    "    print(f\"No features processed. Defaulting TOTAL_FEATURES to {TOTAL_FEATURES}\")\n",
    "\n",
    "\n",
    "def pad_features(f, max_frames=MAX_FRAMES, total_features=TOTAL_FEATURES):\n",
    "    if f.shape[1] < max_frames:\n",
    "        pad_width = max_frames - f.shape[1]\n",
    "        return np.pad(f, ((0, 0), (0, pad_width)), mode='constant')\n",
    "    else:\n",
    "        return f[:, :max_frames]\n",
    "\n",
    "X_padded = [pad_features(f, max_frames=MAX_FRAMES, total_features=TOTAL_FEATURES) for f, _ in features_and_labels]\n",
    "\n",
    "X = np.array(X_padded)\n",
    "X = X[..., np.newaxis]\n",
    "Y = np.array([l for _, l in features_and_labels])\n",
    "\n",
    "print(f\"Final X shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ab7fb9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:47:58.501043Z",
     "iopub.status.busy": "2025-06-22T07:47:58.500840Z",
     "iopub.status.idle": "2025-06-22T07:47:58.517013Z",
     "shell.execute_reply": "2025-06-22T07:47:58.516286Z"
    },
    "papermill": {
     "duration": 0.020138,
     "end_time": "2025-06-22T07:47:58.518059",
     "exception": false,
     "start_time": "2025-06-22T07:47:58.497921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder classes: [array(['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad',\n",
      "       'surprised'], dtype='<U9')]\n",
      "Shape of Y_encoded: (8300, 8)\n",
      "Sample one-hot rows: [[1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(Y).reshape(-1, 1) \n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "Y_encoded = encoder.fit_transform(Y)\n",
    "\n",
    "print(\"Encoder classes:\", encoder.categories_)\n",
    "print(\"Shape of Y_encoded:\", Y_encoded.shape)\n",
    "print(\"Sample one-hot rows:\", Y_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d268a3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:47:58.523694Z",
     "iopub.status.busy": "2025-06-22T07:47:58.523294Z",
     "iopub.status.idle": "2025-06-22T07:47:59.691919Z",
     "shell.execute_reply": "2025-06-22T07:47:59.690963Z"
    },
    "papermill": {
     "duration": 1.172732,
     "end_time": "2025-06-22T07:47:59.693156",
     "exception": false,
     "start_time": "2025-06-22T07:47:58.520424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 5976\n",
      "Validation samples: 664\n",
      "Test samples: 1660\n",
      "Number of unique emotions: 8\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split into 80% train+val and 20% test\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(\n",
    "    X, Y_encoded, test_size=0.2, random_state=42, shuffle=True, stratify=Y\n",
    ")\n",
    "\n",
    "# Step 2: Split the 80% further into 90% train and 10% val\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(\n",
    "    X_temp, Y_temp, test_size=0.10, random_state=42, shuffle=True, stratify=Y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "\n",
    "unique_emotions = len(np.unique(Y))\n",
    "print(f\"Number of unique emotions: {unique_emotions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e046ff2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:47:59.698900Z",
     "iopub.status.busy": "2025-06-22T07:47:59.698643Z",
     "iopub.status.idle": "2025-06-22T07:47:59.702783Z",
     "shell.execute_reply": "2025-06-22T07:47:59.702052Z"
    },
    "papermill": {
     "duration": 0.00824,
     "end_time": "2025-06-22T07:47:59.703905",
     "exception": false,
     "start_time": "2025-06-22T07:47:59.695665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy',mode='max',patience=15,restore_best_weights=True)\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_accuracy',patience=5,verbose=1,factor=0.5,min_lr=0.00001)\n",
    "model_checkpoint = ModelCheckpoint('best_model2_weights.keras', monitor='val_accuracy', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221ec07a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:47:59.709175Z",
     "iopub.status.busy": "2025-06-22T07:47:59.708965Z",
     "iopub.status.idle": "2025-06-22T07:48:02.365800Z",
     "shell.execute_reply": "2025-06-22T07:48:02.365269Z"
    },
    "papermill": {
     "duration": 2.66064,
     "end_time": "2025-06-22T07:48:02.366859",
     "exception": false,
     "start_time": "2025-06-22T07:47:59.706219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750578480.769529      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">175</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">175</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">175</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">175</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">182</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">175</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5376</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">11,536,384</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m175\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m175\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m640\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m175\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m175\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m36,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m182\u001b[0m, \u001b[38;5;34m175\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m295,168\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m590,080\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m5376\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │      \u001b[38;5;34m11,536,384\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m656,384\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │           \u001b[38;5;34m2,056\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,410,504</span> (51.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,410,504\u001b[0m (51.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,407,688</span> (51.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,407,688\u001b[0m (51.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> (11.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,816\u001b[0m (11.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cnn_rnn_model(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # First Block\n",
    "    x = L.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.MaxPooling2D((2, 2))(x)\n",
    "    x = L.Dropout(0.25)(x)\n",
    "\n",
    "    # Second Block\n",
    "    x = L.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.MaxPooling2D((2, 2))(x)\n",
    "    x = L.Dropout(0.25)(x)\n",
    "\n",
    "    # Third Block\n",
    "    x = L.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.MaxPooling2D((2, 2))(x)\n",
    "    x = L.Dropout(0.25)(x)\n",
    "\n",
    "    # Bridge from CNN to RNN\n",
    "    shape = tf.keras.backend.int_shape(x)\n",
    "    x = L.Reshape((shape[1], shape[2] * shape[3]))(x)\n",
    "    \n",
    "    # RNN Back-End\n",
    "    x = L.Bidirectional(L.LSTM(256, return_sequences=True))(x)\n",
    "    x = L.Dropout(0.3)(x)\n",
    "    x = L.Bidirectional(L.LSTM(128, return_sequences=False))(x) # Final LSTM layer\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.4)(x)\n",
    "    \n",
    "    # Classifier Head\n",
    "    x = L.Dense(256, activation='relu')(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Dropout(0.4)(x)\n",
    "    outputs = L.Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model = cnn_rnn_model((TOTAL_FEATURES, MAX_FRAMES, 1), num_classes=8)\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), # Slightly lower learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe34ab93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T07:48:02.374373Z",
     "iopub.status.busy": "2025-06-22T07:48:02.374160Z",
     "iopub.status.idle": "2025-06-22T09:05:36.794140Z",
     "shell.execute_reply": "2025-06-22T09:05:36.793452Z"
    },
    "papermill": {
     "duration": 4654.425247,
     "end_time": "2025-06-22T09:05:36.795588",
     "exception": false,
     "start_time": "2025-06-22T07:48:02.370341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1750578496.024612      19 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/functional_1/dropout_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "I0000 00:00:1750578497.167342      92 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 450ms/step - accuracy: 0.1341 - loss: 3.0971 - val_accuracy: 0.0723 - val_loss: 2.1537 - learning_rate: 5.0000e-05\n",
      "Epoch 2/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.1843 - loss: 2.6690 - val_accuracy: 0.1672 - val_loss: 2.0984 - learning_rate: 5.0000e-05\n",
      "Epoch 3/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.2398 - loss: 2.4502 - val_accuracy: 0.2681 - val_loss: 1.9490 - learning_rate: 5.0000e-05\n",
      "Epoch 4/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.2698 - loss: 2.3419 - val_accuracy: 0.3208 - val_loss: 1.8331 - learning_rate: 5.0000e-05\n",
      "Epoch 5/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.2975 - loss: 2.1632 - val_accuracy: 0.3268 - val_loss: 1.8063 - learning_rate: 5.0000e-05\n",
      "Epoch 6/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.3311 - loss: 2.0576 - val_accuracy: 0.4127 - val_loss: 1.9702 - learning_rate: 5.0000e-05\n",
      "Epoch 7/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.3497 - loss: 1.9839 - val_accuracy: 0.4142 - val_loss: 1.8445 - learning_rate: 5.0000e-05\n",
      "Epoch 8/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.3590 - loss: 1.9354 - val_accuracy: 0.4247 - val_loss: 1.7847 - learning_rate: 5.0000e-05\n",
      "Epoch 9/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.3814 - loss: 1.8615 - val_accuracy: 0.4458 - val_loss: 1.6390 - learning_rate: 5.0000e-05\n",
      "Epoch 10/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.4098 - loss: 1.7597 - val_accuracy: 0.4789 - val_loss: 1.6505 - learning_rate: 5.0000e-05\n",
      "Epoch 11/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.4356 - loss: 1.6805 - val_accuracy: 0.4684 - val_loss: 1.6756 - learning_rate: 5.0000e-05\n",
      "Epoch 12/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.4325 - loss: 1.6416 - val_accuracy: 0.5331 - val_loss: 1.3572 - learning_rate: 5.0000e-05\n",
      "Epoch 13/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.4483 - loss: 1.5442 - val_accuracy: 0.5422 - val_loss: 1.3655 - learning_rate: 5.0000e-05\n",
      "Epoch 14/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.4912 - loss: 1.4778 - val_accuracy: 0.4940 - val_loss: 1.6382 - learning_rate: 5.0000e-05\n",
      "Epoch 15/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.5000 - loss: 1.4167 - val_accuracy: 0.5633 - val_loss: 1.3265 - learning_rate: 5.0000e-05\n",
      "Epoch 16/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.5219 - loss: 1.3652 - val_accuracy: 0.5753 - val_loss: 1.2270 - learning_rate: 5.0000e-05\n",
      "Epoch 17/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.5507 - loss: 1.3008 - val_accuracy: 0.5919 - val_loss: 1.2272 - learning_rate: 5.0000e-05\n",
      "Epoch 18/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.5669 - loss: 1.2046 - val_accuracy: 0.5979 - val_loss: 1.2575 - learning_rate: 5.0000e-05\n",
      "Epoch 19/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.6031 - loss: 1.1311 - val_accuracy: 0.6099 - val_loss: 1.1024 - learning_rate: 5.0000e-05\n",
      "Epoch 20/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 410ms/step - accuracy: 0.6114 - loss: 1.0858 - val_accuracy: 0.6220 - val_loss: 1.1212 - learning_rate: 5.0000e-05\n",
      "Epoch 21/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.6367 - loss: 1.0203 - val_accuracy: 0.6506 - val_loss: 1.1063 - learning_rate: 5.0000e-05\n",
      "Epoch 22/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.6503 - loss: 1.0059 - val_accuracy: 0.6401 - val_loss: 1.1201 - learning_rate: 5.0000e-05\n",
      "Epoch 23/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.6650 - loss: 0.9348 - val_accuracy: 0.6401 - val_loss: 1.0721 - learning_rate: 5.0000e-05\n",
      "Epoch 24/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 410ms/step - accuracy: 0.6684 - loss: 0.8810 - val_accuracy: 0.6792 - val_loss: 0.9736 - learning_rate: 5.0000e-05\n",
      "Epoch 25/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.6997 - loss: 0.8229 - val_accuracy: 0.6988 - val_loss: 0.8655 - learning_rate: 5.0000e-05\n",
      "Epoch 26/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.7198 - loss: 0.7857 - val_accuracy: 0.6837 - val_loss: 0.9648 - learning_rate: 5.0000e-05\n",
      "Epoch 27/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.7341 - loss: 0.7039 - val_accuracy: 0.7003 - val_loss: 0.9118 - learning_rate: 5.0000e-05\n",
      "Epoch 28/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.7460 - loss: 0.7122 - val_accuracy: 0.7199 - val_loss: 0.8406 - learning_rate: 5.0000e-05\n",
      "Epoch 29/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.7554 - loss: 0.6527 - val_accuracy: 0.6913 - val_loss: 0.8275 - learning_rate: 5.0000e-05\n",
      "Epoch 30/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.7725 - loss: 0.6324 - val_accuracy: 0.7575 - val_loss: 0.7284 - learning_rate: 5.0000e-05\n",
      "Epoch 31/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.7942 - loss: 0.5946 - val_accuracy: 0.7229 - val_loss: 0.8081 - learning_rate: 5.0000e-05\n",
      "Epoch 32/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.7934 - loss: 0.5568 - val_accuracy: 0.7123 - val_loss: 0.8332 - learning_rate: 5.0000e-05\n",
      "Epoch 33/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.8045 - loss: 0.5526 - val_accuracy: 0.7922 - val_loss: 0.6728 - learning_rate: 5.0000e-05\n",
      "Epoch 34/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.8089 - loss: 0.5212 - val_accuracy: 0.7666 - val_loss: 0.7180 - learning_rate: 5.0000e-05\n",
      "Epoch 35/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.8412 - loss: 0.4534 - val_accuracy: 0.7861 - val_loss: 0.6411 - learning_rate: 5.0000e-05\n",
      "Epoch 36/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.8438 - loss: 0.4400 - val_accuracy: 0.7681 - val_loss: 0.6777 - learning_rate: 5.0000e-05\n",
      "Epoch 37/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.8743 - loss: 0.3682 - val_accuracy: 0.7274 - val_loss: 0.8802 - learning_rate: 5.0000e-05\n",
      "Epoch 38/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.8768 - loss: 0.3545\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.8767 - loss: 0.3546 - val_accuracy: 0.7590 - val_loss: 0.7236 - learning_rate: 5.0000e-05\n",
      "Epoch 39/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.8819 - loss: 0.3301 - val_accuracy: 0.8072 - val_loss: 0.6023 - learning_rate: 2.5000e-05\n",
      "Epoch 40/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.8936 - loss: 0.3085 - val_accuracy: 0.8102 - val_loss: 0.6158 - learning_rate: 2.5000e-05\n",
      "Epoch 41/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9062 - loss: 0.2697 - val_accuracy: 0.8072 - val_loss: 0.6407 - learning_rate: 2.5000e-05\n",
      "Epoch 42/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9121 - loss: 0.2596 - val_accuracy: 0.7952 - val_loss: 0.6666 - learning_rate: 2.5000e-05\n",
      "Epoch 43/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9065 - loss: 0.2522 - val_accuracy: 0.8072 - val_loss: 0.6184 - learning_rate: 2.5000e-05\n",
      "Epoch 44/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9232 - loss: 0.2319 - val_accuracy: 0.7982 - val_loss: 0.6469 - learning_rate: 2.5000e-05\n",
      "Epoch 45/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.9244 - loss: 0.2255\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9243 - loss: 0.2255 - val_accuracy: 0.7922 - val_loss: 0.6964 - learning_rate: 2.5000e-05\n",
      "Epoch 46/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.9380 - loss: 0.1977 - val_accuracy: 0.8148 - val_loss: 0.6011 - learning_rate: 1.2500e-05\n",
      "Epoch 47/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9239 - loss: 0.2140 - val_accuracy: 0.8072 - val_loss: 0.6456 - learning_rate: 1.2500e-05\n",
      "Epoch 48/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.9358 - loss: 0.1853 - val_accuracy: 0.8223 - val_loss: 0.5789 - learning_rate: 1.2500e-05\n",
      "Epoch 49/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9435 - loss: 0.1719 - val_accuracy: 0.8087 - val_loss: 0.6499 - learning_rate: 1.2500e-05\n",
      "Epoch 50/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9346 - loss: 0.1985 - val_accuracy: 0.8087 - val_loss: 0.6373 - learning_rate: 1.2500e-05\n",
      "Epoch 51/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9488 - loss: 0.1549 - val_accuracy: 0.8148 - val_loss: 0.6085 - learning_rate: 1.2500e-05\n",
      "Epoch 52/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.9482 - loss: 0.1613 - val_accuracy: 0.8328 - val_loss: 0.6119 - learning_rate: 1.2500e-05\n",
      "Epoch 53/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9518 - loss: 0.1515 - val_accuracy: 0.8223 - val_loss: 0.6159 - learning_rate: 1.2500e-05\n",
      "Epoch 54/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9512 - loss: 0.1563 - val_accuracy: 0.8193 - val_loss: 0.6142 - learning_rate: 1.2500e-05\n",
      "Epoch 55/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.9468 - loss: 0.1501 - val_accuracy: 0.8343 - val_loss: 0.5521 - learning_rate: 1.2500e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9536 - loss: 0.1591 - val_accuracy: 0.8223 - val_loss: 0.5843 - learning_rate: 1.2500e-05\n",
      "Epoch 57/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9542 - loss: 0.1411 - val_accuracy: 0.8313 - val_loss: 0.6064 - learning_rate: 1.2500e-05\n",
      "Epoch 58/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9567 - loss: 0.1355 - val_accuracy: 0.8208 - val_loss: 0.6168 - learning_rate: 1.2500e-05\n",
      "Epoch 59/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9538 - loss: 0.1439 - val_accuracy: 0.8193 - val_loss: 0.6557 - learning_rate: 1.2500e-05\n",
      "Epoch 60/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.9652 - loss: 0.1209\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9651 - loss: 0.1209 - val_accuracy: 0.8163 - val_loss: 0.6135 - learning_rate: 1.2500e-05\n",
      "Epoch 61/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9650 - loss: 0.1194 - val_accuracy: 0.8178 - val_loss: 0.6388 - learning_rate: 1.0000e-05\n",
      "Epoch 62/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9605 - loss: 0.1194 - val_accuracy: 0.8238 - val_loss: 0.6296 - learning_rate: 1.0000e-05\n",
      "Epoch 63/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9600 - loss: 0.1233 - val_accuracy: 0.8223 - val_loss: 0.6474 - learning_rate: 1.0000e-05\n",
      "Epoch 64/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9669 - loss: 0.1094 - val_accuracy: 0.8268 - val_loss: 0.5775 - learning_rate: 1.0000e-05\n",
      "Epoch 65/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9677 - loss: 0.1042 - val_accuracy: 0.8087 - val_loss: 0.6581 - learning_rate: 1.0000e-05\n",
      "Epoch 66/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9651 - loss: 0.1116 - val_accuracy: 0.8268 - val_loss: 0.6263 - learning_rate: 1.0000e-05\n",
      "Epoch 67/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9714 - loss: 0.1002 - val_accuracy: 0.8253 - val_loss: 0.6176 - learning_rate: 1.0000e-05\n",
      "Epoch 68/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.9742 - loss: 0.0891 - val_accuracy: 0.8419 - val_loss: 0.5921 - learning_rate: 1.0000e-05\n",
      "Epoch 69/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9714 - loss: 0.0940 - val_accuracy: 0.8117 - val_loss: 0.6718 - learning_rate: 1.0000e-05\n",
      "Epoch 70/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9682 - loss: 0.0978 - val_accuracy: 0.8253 - val_loss: 0.6726 - learning_rate: 1.0000e-05\n",
      "Epoch 71/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9717 - loss: 0.0963 - val_accuracy: 0.8253 - val_loss: 0.6240 - learning_rate: 1.0000e-05\n",
      "Epoch 72/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9702 - loss: 0.0940 - val_accuracy: 0.8343 - val_loss: 0.5878 - learning_rate: 1.0000e-05\n",
      "Epoch 73/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9711 - loss: 0.0958 - val_accuracy: 0.8268 - val_loss: 0.6286 - learning_rate: 1.0000e-05\n",
      "Epoch 74/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.9748 - loss: 0.0884 - val_accuracy: 0.8434 - val_loss: 0.5493 - learning_rate: 1.0000e-05\n",
      "Epoch 75/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9726 - loss: 0.0894 - val_accuracy: 0.8253 - val_loss: 0.6682 - learning_rate: 1.0000e-05\n",
      "Epoch 76/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 400ms/step - accuracy: 0.9738 - loss: 0.0865 - val_accuracy: 0.8238 - val_loss: 0.6515 - learning_rate: 1.0000e-05\n",
      "Epoch 77/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9749 - loss: 0.0889 - val_accuracy: 0.8343 - val_loss: 0.6319 - learning_rate: 1.0000e-05\n",
      "Epoch 78/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9783 - loss: 0.0785 - val_accuracy: 0.8193 - val_loss: 0.7117 - learning_rate: 1.0000e-05\n",
      "Epoch 79/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.9749 - loss: 0.0867 - val_accuracy: 0.8479 - val_loss: 0.6007 - learning_rate: 1.0000e-05\n",
      "Epoch 80/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9707 - loss: 0.0890 - val_accuracy: 0.8343 - val_loss: 0.6036 - learning_rate: 1.0000e-05\n",
      "Epoch 81/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9785 - loss: 0.0745 - val_accuracy: 0.8087 - val_loss: 0.7391 - learning_rate: 1.0000e-05\n",
      "Epoch 82/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9775 - loss: 0.0704 - val_accuracy: 0.8373 - val_loss: 0.6294 - learning_rate: 1.0000e-05\n",
      "Epoch 83/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9786 - loss: 0.0753 - val_accuracy: 0.8404 - val_loss: 0.5958 - learning_rate: 1.0000e-05\n",
      "Epoch 84/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9808 - loss: 0.0760 - val_accuracy: 0.8268 - val_loss: 0.6767 - learning_rate: 1.0000e-05\n",
      "Epoch 85/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.9820 - loss: 0.0605 - val_accuracy: 0.8614 - val_loss: 0.5660 - learning_rate: 1.0000e-05\n",
      "Epoch 86/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9816 - loss: 0.0601 - val_accuracy: 0.8298 - val_loss: 0.6400 - learning_rate: 1.0000e-05\n",
      "Epoch 87/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9808 - loss: 0.0632 - val_accuracy: 0.8193 - val_loss: 0.7054 - learning_rate: 1.0000e-05\n",
      "Epoch 88/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9846 - loss: 0.0556 - val_accuracy: 0.8328 - val_loss: 0.6580 - learning_rate: 1.0000e-05\n",
      "Epoch 89/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9842 - loss: 0.0593 - val_accuracy: 0.8449 - val_loss: 0.6131 - learning_rate: 1.0000e-05\n",
      "Epoch 90/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9858 - loss: 0.0499 - val_accuracy: 0.8404 - val_loss: 0.5993 - learning_rate: 1.0000e-05\n",
      "Epoch 91/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9827 - loss: 0.0584 - val_accuracy: 0.8524 - val_loss: 0.5657 - learning_rate: 1.0000e-05\n",
      "Epoch 92/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9865 - loss: 0.0500 - val_accuracy: 0.8524 - val_loss: 0.5791 - learning_rate: 1.0000e-05\n",
      "Epoch 93/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9861 - loss: 0.0534 - val_accuracy: 0.8343 - val_loss: 0.6338 - learning_rate: 1.0000e-05\n",
      "Epoch 94/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9860 - loss: 0.0488 - val_accuracy: 0.8494 - val_loss: 0.5974 - learning_rate: 1.0000e-05\n",
      "Epoch 95/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9889 - loss: 0.0451 - val_accuracy: 0.8479 - val_loss: 0.6148 - learning_rate: 1.0000e-05\n",
      "Epoch 96/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9870 - loss: 0.0489 - val_accuracy: 0.8464 - val_loss: 0.6142 - learning_rate: 1.0000e-05\n",
      "Epoch 97/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9849 - loss: 0.0459 - val_accuracy: 0.8358 - val_loss: 0.6645 - learning_rate: 1.0000e-05\n",
      "Epoch 98/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 409ms/step - accuracy: 0.9870 - loss: 0.0524 - val_accuracy: 0.8645 - val_loss: 0.5828 - learning_rate: 1.0000e-05\n",
      "Epoch 99/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9866 - loss: 0.0494 - val_accuracy: 0.8539 - val_loss: 0.5990 - learning_rate: 1.0000e-05\n",
      "Epoch 100/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9863 - loss: 0.0457 - val_accuracy: 0.8614 - val_loss: 0.5676 - learning_rate: 1.0000e-05\n",
      "Epoch 101/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9896 - loss: 0.0446 - val_accuracy: 0.8464 - val_loss: 0.5870 - learning_rate: 1.0000e-05\n",
      "Epoch 102/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9847 - loss: 0.0518 - val_accuracy: 0.8630 - val_loss: 0.5765 - learning_rate: 1.0000e-05\n",
      "Epoch 103/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9826 - loss: 0.0573 - val_accuracy: 0.8614 - val_loss: 0.5958 - learning_rate: 1.0000e-05\n",
      "Epoch 104/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9894 - loss: 0.0449 - val_accuracy: 0.8479 - val_loss: 0.6605 - learning_rate: 1.0000e-05\n",
      "Epoch 105/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9862 - loss: 0.0409 - val_accuracy: 0.8404 - val_loss: 0.6176 - learning_rate: 1.0000e-05\n",
      "Epoch 106/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9858 - loss: 0.0450 - val_accuracy: 0.8539 - val_loss: 0.6197 - learning_rate: 1.0000e-05\n",
      "Epoch 107/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.9891 - loss: 0.0445 - val_accuracy: 0.8825 - val_loss: 0.5305 - learning_rate: 1.0000e-05\n",
      "Epoch 108/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9848 - loss: 0.0465 - val_accuracy: 0.8539 - val_loss: 0.6626 - learning_rate: 1.0000e-05\n",
      "Epoch 109/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9913 - loss: 0.0399 - val_accuracy: 0.8554 - val_loss: 0.6299 - learning_rate: 1.0000e-05\n",
      "Epoch 110/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9879 - loss: 0.0408 - val_accuracy: 0.8750 - val_loss: 0.5459 - learning_rate: 1.0000e-05\n",
      "Epoch 111/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9907 - loss: 0.0350 - val_accuracy: 0.8524 - val_loss: 0.6593 - learning_rate: 1.0000e-05\n",
      "Epoch 112/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9916 - loss: 0.0356 - val_accuracy: 0.8569 - val_loss: 0.6398 - learning_rate: 1.0000e-05\n",
      "Epoch 113/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9883 - loss: 0.0373 - val_accuracy: 0.8599 - val_loss: 0.6393 - learning_rate: 1.0000e-05\n",
      "Epoch 114/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9926 - loss: 0.0311 - val_accuracy: 0.8554 - val_loss: 0.6448 - learning_rate: 1.0000e-05\n",
      "Epoch 115/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9934 - loss: 0.0307 - val_accuracy: 0.8494 - val_loss: 0.6984 - learning_rate: 1.0000e-05\n",
      "Epoch 116/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9933 - loss: 0.0325 - val_accuracy: 0.8720 - val_loss: 0.5742 - learning_rate: 1.0000e-05\n",
      "Epoch 117/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9922 - loss: 0.0359 - val_accuracy: 0.8660 - val_loss: 0.6040 - learning_rate: 1.0000e-05\n",
      "Epoch 118/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9899 - loss: 0.0355 - val_accuracy: 0.8479 - val_loss: 0.6546 - learning_rate: 1.0000e-05\n",
      "Epoch 119/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9887 - loss: 0.0385 - val_accuracy: 0.8584 - val_loss: 0.6155 - learning_rate: 1.0000e-05\n",
      "Epoch 120/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9916 - loss: 0.0327 - val_accuracy: 0.8569 - val_loss: 0.6138 - learning_rate: 1.0000e-05\n",
      "Epoch 121/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9903 - loss: 0.0303 - val_accuracy: 0.8389 - val_loss: 0.7503 - learning_rate: 1.0000e-05\n",
      "Epoch 122/200\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9930 - loss: 0.0278 - val_accuracy: 0.8660 - val_loss: 0.5862 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "callbacks = [early_stopping, lr_reduction, model_checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_val, Y_val),\n",
    "    epochs=200, # Increased epochs to allow more training given early stopping\n",
    "    batch_size=64, # Increased batch size\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2019aab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T09:05:37.868833Z",
     "iopub.status.busy": "2025-06-22T09:05:37.868506Z",
     "iopub.status.idle": "2025-06-22T09:05:44.679051Z",
     "shell.execute_reply": "2025-06-22T09:05:44.677986Z"
    },
    "papermill": {
     "duration": 7.310971,
     "end_time": "2025-06-22T09:05:44.680195",
     "exception": false,
     "start_time": "2025-06-22T09:05:37.369224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step\n",
      "Confusion Matrix:\n",
      " [[246   3   9  19   5   2   3   0]\n",
      " [  0 278   0   0   0   1   0   0]\n",
      " [  1   0 129   0   1   0   5   3]\n",
      " [  4   5   0 216   2   0  12   1]\n",
      " [  6  12   2  13 213   3   2   3]\n",
      " [  0   7   2   0   0 103   3   0]\n",
      " [  0  26   1  10   4   1 223   2]\n",
      " [  0   0   0   0   1   0   1  77]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.96      0.86      0.90       287\n",
      "        calm       0.84      1.00      0.91       279\n",
      "     disgust       0.90      0.93      0.91       139\n",
      "     fearful       0.84      0.90      0.87       240\n",
      "       happy       0.94      0.84      0.89       254\n",
      "     neutral       0.94      0.90      0.92       115\n",
      "         sad       0.90      0.84      0.86       267\n",
      "   surprised       0.90      0.97      0.93        79\n",
      "\n",
      "    accuracy                           0.89      1660\n",
      "   macro avg       0.90      0.90      0.90      1660\n",
      "weighted avg       0.90      0.89      0.89      1660\n",
      "\n",
      "Overall Accuracy: 89.46%\n",
      "Macro F1 Score: 89.99%\n",
      "Accuracy for class angry: 85.71%\n",
      "Accuracy for class calm: 99.64%\n",
      "Accuracy for class disgust: 92.81%\n",
      "Accuracy for class fearful: 90.00%\n",
      "Accuracy for class happy: 83.86%\n",
      "Accuracy for class neutral: 89.57%\n",
      "Accuracy for class sad: 83.52%\n",
      "Accuracy for class surprised: 97.47%\n"
     ]
    }
   ],
   "source": [
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=encoder.categories_[0])\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "overall_accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n",
    "\n",
    "macro_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "print(f\"Macro F1 Score: {macro_f1*100:.2f}%\")\n",
    "\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "for idx, acc in enumerate(per_class_accuracy):\n",
    "    print(f\"Accuracy for class {encoder.categories_[0][idx]}: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd315e13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-22T09:05:45.736430Z",
     "iopub.status.busy": "2025-06-22T09:05:45.736136Z",
     "iopub.status.idle": "2025-06-22T09:05:46.101829Z",
     "shell.execute_reply": "2025-06-22T09:05:46.101043Z"
    },
    "papermill": {
     "duration": 0.927658,
     "end_time": "2025-06-22T09:05:46.103357",
     "exception": false,
     "start_time": "2025-06-22T09:05:45.175699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('best_model_improved.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7655516,
     "sourceId": 12155554,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4892.096809,
   "end_time": "2025-06-22T09:05:49.918454",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-22T07:44:17.821645",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
